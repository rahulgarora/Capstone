  ---
title: "Capstone"
author: "Rahul"
date: "November 2, 2016"
output: html_document
---
```{r split echo=FALSE, warning=FALSE, message=FALSE}

library(caret)
library(randomForest)

inTraining <- createDataPartition(df_train_random$Adjusted_Demand, p = .4, list = FALSE)


# save the training and testing sets as data frames
train_1232 <- df_train_random[ inTraining,]
test_1232  <- df_train_random[-inTraining,]


```

```{r ModelRF echo=FALSE, warning=FALSE, message=FALSE}

t0 <- Sys.time()

# fit the randomforest model
model_rf <- randomForest(Adjusted_Demand ~ Product_ID + Sales_this_week.pesos. + Returns_next_week.pesos. +
           Client_ID, data=train_1232, mtry=4, ntree=200)
t1 <- Sys.time()
t1-t0

str(model_rf)

## Cross validation for RF

cv_model <- rfcv(train_1232, train_1232$Adjusted_Demand, cv.fold = 5, mtry=function(p) max(1, floor(sqrt(p))), ntree=200, replace=FALSE, oob_score=TRUE, nodesize=42)

#mtry=M, ntrees=T, ncores=C, nfeatures=F, nrows=R, maxdepth=D_max, is:

#Runtime proportional to: T * F^2 * (R^1.something) * 2^D_max / C

# what are the important variables (via permutation)
model_rf$importance
model_rf$rsq
model_rf$predicted

vi <- varImp(model_rf, type=1)
plot(vi, top=10)


# predict the outcome of the training data
predicted_tr <- predict(model_rf, newdata=train_1232, select = -c(Adjusted_Demand))
actual_tr <- train_1232$Adjusted_Demand
rsq_tr <- 1-sum((actual_tr-predicted_tr)^2)/sum((actual_tr-mean(actual_tr))^2)


# predict the outcome of the testing data
predicted <- predict(model_rf, newdata=test_1232, select = -c(Adjusted_Demand))
actual <- test_1232$Adjusted_Demand
rsq <- 1-sum((actual-predicted)^2)/sum((actual-mean(actual))^2)


```

```{r folds}
library("DAAG")
require(caret)
train_1232_2 <- train_1232
View(train_1232_2)

K=10  # K is the number of each Folds
n= floor(nrow(train_1232_2)/K) #n is the size of each fold

#Partition the First fold
i=1
s1= ((i-1)+ n+1)   # start of the subset
s2= i+n   # end of the subset
subset = s1:s2  # range of the subset

cv.train = train_1232_2[-subset,]
cv.test = train_1232_2[subset,]


##cv.lm(data=train_1232_2, form.lm=mod1, m= 10, plotit = F)

##flds <- createFolds(train_1232_2, k = 900, list = TRUE, returnTrain = FALSE)
##names(flds)[1] <- "train"
##train_new <- train_1232_2[flds[[10]],]



```

```{r kfold}

# define training control
#train_control <- trainControl(method="cv", number=10)
# fix the parameters of the algorithm
#grid <- expand.grid(.fL=c(0), .usekernel=c(FALSE))
# train the model
model_rf_1 <- randomForest(Adjusted_Demand ~ Product_ID + Sales_this_week.pesos. + Returns_next_week.pesos. +
           Client_ID, data=train_1232, trControl=train_control, method="oob", tuneGrid=grid, mtry=4, ntree=200, replace=FALSE, importance=TRUE, oob_score=TRUE, nodesize=42)

model_rf_2 <- randomForest(Adjusted_Demand ~ Product_ID + Sales_this_week.pesos. + Returns_next_week.pesos. +
           Client_ID, data=train_1232, trControl=train_control, method="oob", tuneGrid=grid, mtry=4, ntree=300, replace=FALSE, importance=TRUE, oob_score=TRUE, nodesize=42)

model_rf_3 <- randomForest(Adjusted_Demand ~ Product_ID + Sales_this_week.pesos. + Returns_next_week.pesos. +
           Client_ID, data=train_1232, trControl=train_control, method="oob", tuneGrid=grid, mtry=4, ntree=400, replace=FALSE, importance=TRUE, oob_score=TRUE, nodesize=42)

model_rf_4 <- randomForest(Adjusted_Demand ~ Product_ID + Sales_this_week.pesos. + Returns_next_week.pesos. +
           Client_ID, data=train_1232, trControl=train_control, method="oob", tuneGrid=grid, mtry=4, ntree=500, replace=FALSE, importance=TRUE, oob_score=TRUE, nodesize=42)

# summarize results
print(model)

model$inbag
```


#### Random Forest Model Boosting: K-Fold and Grid Search Cross Validation  

```{r test1 echo=FALSE, message=FALSE, warning=FALSE}
# ensure results are repeatable
set.seed(123)
#inTraining <- createDataPartition(listings$log_price, p = .8, list = FALSE)
#training <- listings[ inTraining,]
#testing  <- listings[-inTraining,]

# Manual Grid Search
control_new <- trainControl(method="repeatedcv", 
                        number=10, 
                        repeats=1, 
                        search="grid")
tunegrid_new <- expand.grid(.mtry=c(4))
modellist_new <- list()
metric_new = "RMSE"

#For loop of gridsearch
for (ntree in c(50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 600, 650, 700)) {
	set.seed(123)
	fit <- train(Adjusted_Demand ~ Product_ID + Sales_this_week.pesos. + Returns_next_week.pesos. +
           Client_ID,
	             data=test_1232, 
	             method="rf", 
	             metric=metric_new, 
	             tuneGrid=tunegrid_new, 
	             trControl=control_new, 
	             ntree=ntree)
	key <- toString(ntree)
	modellist_new[[key]] <- fit
}

##out <- capture.output(fit)
##cat("My title", out, file="C:\\Users\\rahuaror\\Documents\\Capstone\\Bakery Inventory\\Data_analysis\\model_fit_test_5.txt", sep="n", append=TRUE)

##out <- capture.output(modellist_new)
##cat("My title", out, file="C:\\Users\\rahuaror\\Documents\\Capstone\\Bakery Inventory\\Data_analysis\\model_test_5.txt", sep="n", append=TRUE)

#### compare results
results <- resamples(modellist_new)
##write.csv(results, file = 'C:\\Users\\rahuaror\\Documents\\Capstone\\Bakery Inventory\\Data_analysis\\results_test_5.csv')

summary <- summary(results)
summaryout <- capture.output(summary)
##write.csv(summaryout, file = 'C:\\Users\\rahuaror\\Documents\\Capstone\\Bakery Inventory\\Data_analysis\\summary_test_ntree.csv')


# predict the outcome of the training data for ntree = 300
predicted_tr <- predict(modellist_new[['300']], newdata=train_1232, select = -c(Adjusted_Demand))
actual_tr <- train_1232$Adjusted_Demand
rsq_tr <- 1-sum((actual_tr-predicted_tr)^2)/sum((actual_tr-mean(actual_tr))^2)

# predict the outcome of the testing data for ntree =300
predicted <- predict(modellist_new[['300']], newdata=test_1232, select = -c(Adjusted_Demand))
actual <- test_1232$Adjusted_Demand
rsq <- 1-sum((actual-predicted)^2)/sum((actual-mean(actual))^2)
```


#### Random Forest Model Boosting: K-Fold and Grid Search Cross Validation  

```{r test2 echo=FALSE, message=FALSE, warning=FALSE}
# ensure results are repeatable
set.seed(1234)
#inTraining <- createDataPartition(listings$log_price, p = .8, list = FALSE)
#training <- listings[ inTraining,]
#testing  <- listings[-inTraining,]

# Manual Grid Search
control_new_2 <- trainControl(method="repeatedcv", 
                        number=10, 
                        repeats=1, 
                        search="grid")
tunegrid_new_2 <- expand.grid(.mtry=c(4))
modellist_new_2 <- list()
metric_new_2 = "RMSE"

#For loop of gridsearch
for (ntree in c(300, 400)) {
	set.seed(1234)
	fit_2 <- train(Adjusted_Demand ~ Product_ID + Sales_this_week.pesos. + Returns_next_week.pesos. +
           Client_ID,
	             data=train_1232, 
	             method="rf", 
	             metric=metric_new_2, 
	             tuneGrid=tunegrid_new_2, 
	             trControl=control_new_2, 
	             ntree=ntree)
	key <- toString(ntree)
	modellist_new_2[[key]] <- fit_2
}

##out_2 <- capture.output(modellist_new_2)
##cat("Data_output$", out_2, file="C:\\Users\\rahuaror\\Documents\\Capstone\\Bakery Inventory\\Data_analysis\\model_2.txt", sep="n", append=TRUE)

#### compare results
results_2 <- resamples(modellist_new_2)
summary_2 <- summary(results_2)

##write.csv(results_2, file = 'C:\\Users\\rahuaror\\Documents\\Capstone\\Bakery Inventory\\Data_analysis\\results_2.csv')
##summaryout_2 <- capture.output(summary_2)
##write.csv(summaryout_2, file = 'C:\\Users\\rahuaror\\Documents\\Capstone\\Bakery Inventory\\Data_analysis\\summary_2.csv')


# predict the outcome of the training data for ntree = 300
predicted_tr_2 <- predict(modellist_new_2[['300']], newdata=train_1232, select = -c(Adjusted_Demand))
actual_tr_2 <- train_1232$Adjusted_Demand
rsq_tr_2 <- 1-sum((actual_tr_2-predicted_tr_2)^2)/sum((actual_tr_2-mean(actual_tr_2))^2)

# predict the outcome of the testing data for ntree =300
predicted_2 <- predict(modellist_new_2[['300']], newdata=test_1232, select = -c(Adjusted_Demand))
actual_2 <- test_1232$Adjusted_Demand
rsq_2 <- 1-sum((actual_2-predicted_2)^2)/sum((actual_2-mean(actual_2))^2)
```

```{r final_test}

df_test_final <- read.csv('C:\\Users\\rahuaror\\Documents\\Rahul\\SpingBoard\\HugeDataSet\\train_week9_random_subset.csv')

# predict the outcome of the Validation data (Data unseen by the model)
predicted_validation <- predict(model_rf, newdata=df_test_final, select = -c(Adjusted_Demand))
actual_validation <- df_test_final$Adjusted_Demand
rsq_validation <- 1-sum((actual_validation-predicted_validation)^2)/sum((actual_validation-mean(actual_validation))^2)


rmlse <- function(model_rf) { 
  y <- train_1232$Adjusted_Demand
  y.pred <- predict(model_rf, df_test_final)
  return(sqrt(1/length(y)*sum((log(y.pred +1)-log(train_1232$Adjusted_Demand +1))^2)))
}

rmlse(model_rf)

```